{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import multilabel_confusion_matrix\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom PIL import Image\nfrom skimage.color import rgb2gray\nfrom scipy import ndimage as ndi\nimport cv2\nimport os\nfrom os import listdir\nfrom sklearn.utils import shuffle\nimport keras\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import SGD\nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint\nimport numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nimport pandas as pd\nimport PIL\nfrom PIL import Image\nfrom skimage.color import rgb2gray\nfrom scipy import ndimage as ndi\nimport os\nfrom sklearn.utils import shuffle\nimport keras\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom keras.optimizers import gradient_descent_v2 \nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import LeakyReLU \nfrom keras.utils.vis_utils import plot_model\nfrom numpy import ones \nfrom numpy import zeros \nfrom numpy.random import rand \nfrom numpy.random import randint\nfrom keras.layers import Reshape\nfrom keras.layers import Conv2DTranspose \nimport pickle\nimport tensorflow as tf\nfrom numpy.random import randn \nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_circles\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nget_ipython().run_line_magic('matplotlib', 'inline')\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nprint('Tensorflow version:', tf.__version__)\n\n\n\n\ndirectory_root = \"../input/tomato-grape/Dataset/Grape/Train/Grape___healthy\"\nprint(len(listdir(directory_root)))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n                \n        for single_plant_disease_image in plant_disease_folder_list :\n            if single_plant_disease_image == \".DS_Store\" :\n                plant_disease_folder_list.remove(single_plant_disease_image)\n\n        for image in plant_disease_folder_list:\n            image_directory = f\"{directory_root}/{plant_folder}/{image}\"\n            if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                image_list.append(image_directory)\n                label_list.append(plant_folder)\n    print(\"[INFO] Image loading completed\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_info = pd.DataFrame({'image_path':image_list,'label':label_list})\nprint(img_info.head())\nprint(len(img_info))\n\n\n\n\n#new column (empty)\nimg_info[\"labels_integer\"] = None\n#index of new column\nindex_labels_integer = img_info.columns.get_loc(\"labels_integer\")\n#index of species column\nindex_species = img_info.columns.get_loc(\"label\")\n#to assign numeric labels starting with 0 for the first species\nk = 0 \nfor i in range(len(img_info)):\n    if i == 0:\n        img_info.iloc[i, index_labels_integer] = k #here, k == 0\n    if i > 0:\n        if img_info.iloc[i-1, index_species] == img_info.iloc[i, index_species]:\n            img_info.iloc[i, index_labels_integer] = k\n        else:\n            k += 1\n            img_info.iloc[i, index_labels_integer] = k\nimg_info.tail()\n\nimg_info = shuffle(img_info)\nlist_vectors = []\n\nfor image_path in img_info.image_path:\n    #read as rgb array\n    img = Image.open(image_path)\n    size = (128, 128)\n    img = img.resize(size, PIL.Image.ANTIALIAS)  \n    img_array = np.array(img)\n    #append image vector to list\n    list_vectors.append(img_array)\n    \nprint(len(list_vectors))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.stack((list_vectors))\nY =  img_info['labels_integer']\nprint(X.shape)\n\nY_one_hot = keras.utils.to_categorical(Y, num_classes=10)\nprint(Y.shape, Y_one_hot.shape)\n\nnp.savez(\"x_images_arrayscnn\", X)\nnp.savez(\"y_numeric_labelscnn\", Y_one_hot)\n\nx_npz = np.load(\"x_images_arrayscnn.npz\")\nX = x_npz['arr_0']\n\ny_npz = np.load(\"y_numeric_labelscnn.npz\")\nY_one_hot = y_npz['arr_0']\n\nprint(X.shape)\n\nsplit_train = 0.8 #train 0.8, validate 0.1, test 0.1\nsplit_val = 0.9\nindex_train = int(split_train*len(X))\nindex_val = int(split_val*len(X))\n\nX_train = X[:index_train]\nX_val = X[index_train:index_val]\nX_test = X[index_val:]\n\nY_train = Y_one_hot[:index_train]\nY_val = Y_one_hot[index_train:index_val]\nY_test = Y_one_hot[index_val:]\n\nprint(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlabel_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)\n\n\n\n\ninput_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]) \nnum_classes = 10\n\n\n\n\naug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True, fill_mode=\"nearest\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_discriminator(in_shape=(128,128,3)):\n    model = Sequential()\n      #Normal\n    model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape)) \n    model.add(LeakyReLU(alpha=0.2))\n      #Downsample\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n      #Downsample\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n      #Downsample\n    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n      #Downsample\n    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n      #Downsample\n    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n      #classifier\n    model.add(Flatten()) \n    model.add(Dropout(0.4)) \n    model.add(Dense(1, activation='sigmoid')) \n      #compile model\n    opt = Adam(lr=0.0002, beta_1=0.5) \n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = define_discriminator() \n# summarize the model \nmodel.summary() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_generator(latent_dim): \n    model = Sequential() \n  # foundation for 4x4 image \n    n_nodes = 256 * 4 * 4 \n    model.add(Dense(n_nodes, input_dim=latent_dim)) \n    model.add(LeakyReLU(alpha=0.2)) \n    model.add(Reshape((4, 4, 256))) \n  # upsample to 8x8 \n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')) \n    model.add(LeakyReLU(alpha=0.2)) \n  # upsample to 16x16 \n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')) \n    model.add(LeakyReLU(alpha=0.2))\n  # upsample to 32x32 \n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2)) \n  # upsample to 64x64 \n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')) \n    model.add(LeakyReLU(alpha=0.2)) \n  # upsample to 128x128 \n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')) \n    model.add(LeakyReLU(alpha=0.2)) \n  # output layer \n    model.add(Conv2D(3, (3,3), activation='tanh', padding='same')) \n    return model\n    model.add(Conv2D(128, padding=\"same\", kernel_size=3))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_dim = 100 \n# define the generator model \nmodel = define_generator(latent_dim) \n# summarize the model \nmodel.summary() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_gan(g_model, d_model): \n  # make weights in the discriminator not trainable \n    d_model.trainable = False \n    # connect them \n    model = Sequential() \n  # add generator \n    model.add(g_model) \n  # add the discriminator \n    model.add(d_model) \n  # compile model \n    opt = Adam(lr=0.0002, beta_1=0.5) \n    model.compile(loss='binary_crossentropy', optimizer=opt) \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_dim = 100 \n# create the discriminator \nd_model = define_discriminator() \n# create the generator \ng_model = define_generator(latent_dim) \n# create the gan \ngan_model = define_gan(g_model, d_model) \n# summarize gan model \ngan_model.summary() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_real_samples():\n  # convert from unsigned ints to floats \n    X = X_train.astype('float32') \n  # scale from [0,255] to [-1,1] \n    X = (X - 127.5) / 127.5 \n    return X\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_real_samples(dataset, n_samples): \n  # choose random instances\n    ix = randint(0, dataset.shape[0], n_samples) \n  # retrieve selected images \n    X = dataset[ix] \n  # generate 'real' class labels (1)\n    y = ones((n_samples, 1)) \n    return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_latent_points(latent_dim, n_samples):\n   # generate points in the latent space \n    x_input = randn(latent_dim * n_samples) \n   # reshape into a batch of inputs for the network \n    x_input = x_input.reshape(n_samples, latent_dim) \n    return x_input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_fake_samples(g_model, latent_dim, n_samples): \n  # generate points in latent space\n    x_input = generate_latent_points(latent_dim, n_samples) \n  # predict outputs \n    X = g_model.predict(x_input) \n  # create 'fake' class labels (0) \n    y = zeros((n_samples, 1)) \n    return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_plot(examples, epoch, n=10): \n  # scale from [-1,1] to [0,1] \n    examples = (examples + 1) / 2.0 \n  # plot images \n    for i in range(n * n): \n    # define subplot \n        plt.subplot(n, n, 1 + i) \n    # turn off axis \n        plt.axis('off') \n    # plot raw pixel data \n        plt.imshow(examples[i]) \n  # save plot to file \n    filename = 'Grape_healthy_e%03d.png' % (epoch+1)\n    plt.savefig(filename) \n    plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150): \n  # prepare real samples \n    X_real, y_real = generate_real_samples(dataset, n_samples) \n  # evaluate discriminator on real examples \n    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0) \n  # prepare fake examples \n    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples) \n  # evaluate discriminator on fake examples \n    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0) \n  # summarize discriminator performance \n    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n  # save plot \n    save_plot(x_fake, epoch) \n  # save the generator model tile file \n    filename = 'Grape_healthy_%03d.h5' % (epoch+1) \n    g_model.save(filename)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=16): \n    bat_per_epo = int(dataset.shape[0] / n_batch) \n    half_batch = int(n_batch / 2) \n  # manually enumerate epochs \n    for i in range(n_epochs): \n    # enumerate batches over the training set \n        for j in range(bat_per_epo):\n      # get randomly selected 'real' samples \n            X_real, y_real = generate_real_samples(dataset, half_batch) \n      # update discriminator model weights \n            d_loss1, _ = d_model.train_on_batch(X_real, y_real) \n      # generate 'fake' examples \n            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n      # update discriminator model weights \n            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake) \n      # prepare points in latent space as input for the generator \n            X_gan = generate_latent_points(latent_dim, n_batch) \n      # create inverted labels for the fake samples \n            y_gan = ones((n_batch, 1)) \n      # update the generator via the discriminator's error \n            g_loss = gan_model.train_on_batch(X_gan, y_gan) \n      # summarize loss on this batch \n            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n    # evaluate the model performance, sometimes \n    if (i+1) % 10 == 0: \n        summarize_performance(i, g_model, d_model, dataset, latent_dim)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_dim = 100 \n# create the discriminator \nd_model = define_discriminator() \n# create the generator \ng_model = define_generator(latent_dim) \n# create the gan \ngan_model = define_gan(g_model, d_model) \n# summarize gan model \ngan_model.summary() \n# load image data \ndataset = load_real_samples() \n# train model \ntrain(g_model, d_model, gan_model, dataset, latent_dim)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_plot(X_train, 1, 10)\nplt.figure(figsize=(10,10))\nfor i in range(100):\n    plt.subplot(10,10,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train[i], cmap=plt.cm.binary)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}